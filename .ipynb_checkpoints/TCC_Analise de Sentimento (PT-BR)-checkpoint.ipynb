{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b9e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/matheussilva/anaconda3/envs/p3workshop/bin/python\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import system\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# imdb_train = pd.read_csv('datasets/csv/imdb_train.csv')\n",
    "# imdb_test = pd.read_csv('datasets/csv/imdb_test.csv')\n",
    "\n",
    "iac_train = pd.read_csv('datasets/csv/iac_convinceme_train.csv', sep= \";\")\n",
    "iac_test = pd.read_csv('datasets/csv/iac_create_debate_test.csv', sep= \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b96a8927",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/vectorized_data/X_train_bigram_tf_idf.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sb/lc_nz9bj0pdd7ztvtfbbsrw40000gn/T/ipykernel_19778/228070646.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;31m# Load created model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0mX_train_bigram_tf_idf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_npz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/vectorized_data/X_train_bigram_tf_idf.npz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/p3workshop/lib/python3.7/site-packages/scipy/sparse/_matrix_io.py\u001b[0m in \u001b[0;36mload_npz\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\"\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mPICKLE_KWARGS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mmatrix_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'format'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p3workshop/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/vectorized_data/X_train_bigram_tf_idf.npz'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from joblib import dump, load # used for saving and loading sklearn objects\n",
    "from scipy.sparse import save_npz, load_npz # used for saving and loading sparse matrices\n",
    "\n",
    "# system(\"mkdir datasets/data_preprocessors\")\n",
    "# system(\"mkdir datasets/vectorized_data\")\n",
    "\n",
    "# Unigram Counts\n",
    "\n",
    "unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "# unigram_vectorizer.fit(imdb_train['text'].values)\n",
    "unigram_vectorizer.fit(iac_train['text'].values)\n",
    "\n",
    "dump(unigram_vectorizer, 'datasets/data_preprocessors/unigram_vectorizer.joblib')\n",
    "\n",
    "# unigram_vectorizer = load('data_preprocessors/unigram_vectorizer.joblib')\n",
    "\n",
    "# X_train_unigram = unigram_vectorizer.transform(imdb_train['text'].values)\n",
    "X_train_unigram = unigram_vectorizer.transform(iac_train['text'].values)\n",
    "\n",
    "# Save new model\n",
    "# save_npz('datasets/vectorized_data/X_train_unigram.npz', X_train_unigram)\n",
    "\n",
    "# Load created model\n",
    "X_train_unigram = load_npz('datasets/vectorized_data/X_train_unigram.npz')\n",
    "\n",
    "\n",
    "# Unigram Tf-Idf\n",
    "\n",
    "unigram_tf_idf_transformer = TfidfTransformer()\n",
    "unigram_tf_idf_transformer.fit(X_train_unigram)\n",
    "\n",
    "dump(unigram_tf_idf_transformer, 'datasets/data_preprocessors/unigram_tf_idf_transformer.joblib')\n",
    "\n",
    "# unigram_tf_idf_transformer = load('datasets/data_preprocessors/unigram_tf_idf_transformer.joblib')\n",
    "\n",
    "X_train_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_train_unigram)\n",
    "\n",
    "# Save new model\n",
    "# save_npz('datasets/vectorized_data/X_train_unigram_tf_idf.npz', X_train_unigram_tf_idf)\n",
    "\n",
    "# Load created model\n",
    "X_train_unigram_tf_idf = load_npz('datasets/vectorized_data/X_train_unigram_tf_idf.npz')\n",
    "\n",
    "#-----------------------------------\n",
    "\n",
    "# Bigram Counts\n",
    "\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "# bigram_vectorizer.fit(imdb_train['text'].values)\n",
    "bigram_vectorizer.fit(iac_train['text'].values)\n",
    "\n",
    "dump(bigram_vectorizer, 'datasets/data_preprocessors/bigram_vectorizer.joblib')\n",
    "\n",
    "# bigram_vectorizer = load('data_preprocessors/bigram_vectorizer.joblib')\n",
    "\n",
    "# X_train_bigram = bigram_vectorizer.transform(imdb_train['text'].values)\n",
    "X_train_bigram = bigram_vectorizer.transform(iac_train['text'].values)\n",
    "\n",
    "# Save new model\n",
    "# save_npz('datasets/vectorized_data/X_train_bigram.npz', X_train_bigram)\n",
    "\n",
    "# Load created model\n",
    "X_train_bigram = load_npz('datasets/vectorized_data/X_train_bigram.npz')\n",
    "\n",
    "\n",
    "# Bigram Tf-Idf\n",
    "\n",
    "bigram_tf_idf_transformer = TfidfTransformer()\n",
    "bigram_tf_idf_transformer.fit(X_train_bigram)\n",
    "\n",
    "dump(bigram_tf_idf_transformer, 'datasets/data_preprocessors/bigram_tf_idf_transformer.joblib')\n",
    "\n",
    "# bigram_tf_idf_transformer = load('datasets/data_preprocessors/bigram_tf_idf_transformer.joblib')\n",
    "\n",
    "X_train_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_train_bigram)\n",
    "\n",
    "# Save new model\n",
    "save_npz('datasets/vectorized_data/X_train_bigram_tf_idf.npz', X_train_bigram_tf_idf)\n",
    "\n",
    "# Load created model\n",
    "X_train_bigram_tf_idf = load_npz('datasets/vectorized_data/X_train_bigram_tf_idf.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371db9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
